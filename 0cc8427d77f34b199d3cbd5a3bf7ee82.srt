WEBVTT

1
00:00:00.003 --> 00:00:01.001
- [Instructor] Alright,

2
00:00:01.001 --> 00:00:02.008
so one use case that I've been exploring

3
00:00:02.008 --> 00:00:04.003
that I'm really excited about

4
00:00:04.003 --> 00:00:08.007
and impressed with is using tools like ChatGPT and Bard

5
00:00:08.007 --> 00:00:11.000
to collaborate on things like data prep

6
00:00:11.000 --> 00:00:12.009
and exploratory analysis.

7
00:00:12.009 --> 00:00:14.000
It's such a great way

8
00:00:14.000 --> 00:00:17.004
to leverage the conversational nature of these tools

9
00:00:17.004 --> 00:00:20.001
and actually learn quite a bit along the way.

10
00:00:20.001 --> 00:00:23.001
So let me show you an example of what this might look like.

11
00:00:23.001 --> 00:00:26.005
Here in ChatGPT, I'm going to drop in a prompt like this.

12
00:00:26.005 --> 00:00:30.007
"I just exported a raw CSV file containing web traffic data.

13
00:00:30.007 --> 00:00:34.001
Could you please act like a data quality assurance engineer

14
00:00:34.001 --> 00:00:37.002
and give me a step-by-step plan to help me QA

15
00:00:37.002 --> 00:00:39.003
and prepare my data for analysis?"

16
00:00:39.003 --> 00:00:42.003
So you can see I'm really trying to set clear context here

17
00:00:42.003 --> 00:00:43.004
with this prompt.

18
00:00:43.004 --> 00:00:46.005
I'm describing the type of data that I'm analyzing.

19
00:00:46.005 --> 00:00:50.005
I'm specifying the role that I want ChatGPT to play,

20
00:00:50.005 --> 00:00:51.009
and I'm providing clear guidance

21
00:00:51.009 --> 00:00:54.006
on the type of output that I'm looking for,

22
00:00:54.006 --> 00:00:56.006
a step-by-step plan.

23
00:00:56.006 --> 00:00:59.002
So let's go ahead and give this a shot

24
00:00:59.002 --> 00:01:01.004
and see how this does.

25
00:01:01.004 --> 00:01:02.004
So, of course,

26
00:01:02.004 --> 00:01:03.009
I'd be happy to help you.

27
00:01:03.009 --> 00:01:07.006
Here's a step-by-step plan that you can follow.

28
00:01:07.006 --> 00:01:10.009
Understand the data, validate data integrity,

29
00:01:10.009 --> 00:01:12.008
follow these data cleaning steps

30
00:01:12.008 --> 00:01:16.001
for handling missing values, duplicates,

31
00:01:16.001 --> 00:01:18.001
got some data transformation steps here,

32
00:01:18.001 --> 00:01:20.005
like parsing or aggregating the data,

33
00:01:20.005 --> 00:01:21.009
look at data formatting,

34
00:01:21.009 --> 00:01:23.006
consistency and integrity,

35
00:01:23.006 --> 00:01:25.003
check for outliers,

36
00:01:25.003 --> 00:01:26.003
document the data.

37
00:01:26.003 --> 00:01:27.005
That's a nice one.

38
00:01:27.005 --> 00:01:30.002
And then finally, once you've completed the QA process,

39
00:01:30.002 --> 00:01:32.004
you can then explore the data further

40
00:01:32.004 --> 00:01:35.006
by visualizing it and so on and so forth.

41
00:01:35.006 --> 00:01:37.000
Love this note at the end.

42
00:01:37.000 --> 00:01:39.005
Remember to keep backups of your original data

43
00:01:39.005 --> 00:01:42.006
and work on a separate copy during the QA process

44
00:01:42.006 --> 00:01:45.001
if you need to refer back to the original data.

45
00:01:45.001 --> 00:01:47.008
So overall, really happy with this response.

46
00:01:47.008 --> 00:01:49.002
It's really thorough.

47
00:01:49.002 --> 00:01:53.002
It does truly hit on some of the most important data prep

48
00:01:53.002 --> 00:01:55.008
and QA tasks that you need to be aware of,

49
00:01:55.008 --> 00:01:57.009
along with some that maybe you weren't.

50
00:01:57.009 --> 00:02:00.000
So really, really solid start.

51
00:02:00.000 --> 00:02:02.004
So maybe you start following these steps

52
00:02:02.004 --> 00:02:04.007
and you do find some missing values,

53
00:02:04.007 --> 00:02:05.006
well, you could follow up,

54
00:02:05.006 --> 00:02:07.004
and say, "Hey, I see some missing values.

55
00:02:07.004 --> 00:02:09.006
How should I handle them?"

56
00:02:09.006 --> 00:02:11.000
And now ChatGPT, again,

57
00:02:11.000 --> 00:02:13.005
because it has all of that context,

58
00:02:13.005 --> 00:02:14.003
it's going to say,

59
00:02:14.003 --> 00:02:17.000
yep, handling missing values is an important step.

60
00:02:17.000 --> 00:02:19.002
It depends on the nature of the data

61
00:02:19.002 --> 00:02:21.001
and the specific analysis goals.

62
00:02:21.001 --> 00:02:23.002
Here are a few common strategies,

63
00:02:23.002 --> 00:02:24.007
removing rows,

64
00:02:24.007 --> 00:02:27.008
imputing values for different types of data,

65
00:02:27.008 --> 00:02:30.009
flagging missing values with a binary column,

66
00:02:30.009 --> 00:02:33.003
or using your domain expertise

67
00:02:33.003 --> 00:02:35.002
to either figure out how to impute them

68
00:02:35.002 --> 00:02:38.000
or decide whether they should be kept or removed.

69
00:02:38.000 --> 00:02:40.003
Again, some good best practices here.

70
00:02:40.003 --> 00:02:41.005
Remember, the chosen approach

71
00:02:41.005 --> 00:02:43.001
should align with the characteristics of your data

72
00:02:43.001 --> 00:02:45.001
and the analysis objectives.

73
00:02:45.001 --> 00:02:47.009
And you should always document and communicate the method.

74
00:02:47.009 --> 00:02:49.002
Love this response.

75
00:02:49.002 --> 00:02:50.009
This is exactly the type of guidance

76
00:02:50.009 --> 00:02:53.005
that I would give an actual student or learner

77
00:02:53.005 --> 00:02:54.007
in the real world.

78
00:02:54.007 --> 00:02:57.009
So overall, great output there as well.

79
00:02:57.009 --> 00:03:00.003
And now let's take it kind of one step further,

80
00:03:00.003 --> 00:03:03.002
and say, all right, now my data's looking good.

81
00:03:03.002 --> 00:03:04.003
Now, can you provide a plan

82
00:03:04.003 --> 00:03:06.005
for conducting some data profiling

83
00:03:06.005 --> 00:03:10.008
and exploratory analysis in Excel?

84
00:03:10.008 --> 00:03:12.005
It's going to give us another plan here.

85
00:03:12.005 --> 00:03:16.007
It's going to talk about common data profiling tools,

86
00:03:16.007 --> 00:03:18.004
calculating summary statistics,

87
00:03:18.004 --> 00:03:22.001
like sums, averages, mins, max counts,

88
00:03:22.001 --> 00:03:25.003
some data visualization advice here,

89
00:03:25.003 --> 00:03:28.002
some tips for filtering and sorting,

90
00:03:28.002 --> 00:03:31.005
using relationships if you're working with multiple tables,

91
00:03:31.005 --> 00:03:33.007
validating the data, documenting.

92
00:03:33.007 --> 00:03:35.004
So again, really good tips.

93
00:03:35.004 --> 00:03:37.002
I like that it gives you examples

94
00:03:37.002 --> 00:03:39.006
of specific formulas and functions

95
00:03:39.006 --> 00:03:42.001
or tools that can help you do these things.

96
00:03:42.001 --> 00:03:43.008
And this is really just an example

97
00:03:43.008 --> 00:03:46.002
of how this type of conversation can go,

98
00:03:46.002 --> 00:03:47.004
but really thorough.

99
00:03:47.004 --> 00:03:50.003
It's very accurate from my experience.

100
00:03:50.003 --> 00:03:51.005
And again, it's a great way

101
00:03:51.005 --> 00:03:54.001
to kind of learn these best practices

102
00:03:54.001 --> 00:03:55.009
as you're using these tools.

103
00:03:55.009 --> 00:03:57.000
So for this one, let's go ahead

104
00:03:57.000 --> 00:04:00.004
and actually test the same conversation flow in Bard

105
00:04:00.004 --> 00:04:02.003
and see how it compares.

106
00:04:02.003 --> 00:04:04.006
All right, so we'll start with that same first prompt.

107
00:04:04.006 --> 00:04:09.000
Just exported the raw CSV file containing web traffic data.

108
00:04:09.000 --> 00:04:12.002
And let's see what we get back from Bard.

109
00:04:12.002 --> 00:04:14.009
All right, so here's a step-by-step plan,

110
00:04:14.009 --> 00:04:16.002
review the data dictionary,

111
00:04:16.002 --> 00:04:18.007
check for missing values, check for duplicates,

112
00:04:18.007 --> 00:04:20.002
data integrity,

113
00:04:20.002 --> 00:04:21.006
clean it, prepare it.

114
00:04:21.006 --> 00:04:24.002
So covering a lot of those same kind of key tips

115
00:04:24.002 --> 00:04:26.007
that we saw from ChatGPT.

116
00:04:26.007 --> 00:04:28.003
It's giving some additional tips here,

117
00:04:28.003 --> 00:04:30.003
use a variety of tools,

118
00:04:30.003 --> 00:04:31.003
be proactive,

119
00:04:31.003 --> 00:04:32.009
get help from a data expert.

120
00:04:32.009 --> 00:04:34.003
I like that one.

121
00:04:34.003 --> 00:04:35.005
So pretty similar.

122
00:04:35.005 --> 00:04:37.002
I like that response as well.

123
00:04:37.002 --> 00:04:38.009
No complaints there.

124
00:04:38.009 --> 00:04:41.009
Let's kind of add our follow up prompt here.

125
00:04:41.009 --> 00:04:46.004
I see some missing values. How should I handle them?

126
00:04:46.004 --> 00:04:47.009
All right, again, similar response.

127
00:04:47.009 --> 00:04:50.002
So you can delete them, impute them.

128
00:04:50.002 --> 00:04:53.003
Here are different types of imputation methods.

129
00:04:53.003 --> 00:04:55.002
And then it offers some tips here, right?

130
00:04:55.002 --> 00:04:57.006
Be aware of the limitations, test different methods,

131
00:04:57.006 --> 00:04:59.002
consult with an expert.

132
00:04:59.002 --> 00:05:03.006
Again, pretty similar response here compared to ChatGPT.

133
00:05:03.006 --> 00:05:06.001
And then let's do our final prompt here,

134
00:05:06.001 --> 00:05:08.000
just like before.

135
00:05:08.000 --> 00:05:10.005
Provide a plan for conducting some data profiling

136
00:05:10.005 --> 00:05:15.003
and exploratory analysis.

137
00:05:15.003 --> 00:05:18.009
All right, so this is what data profiling is.

138
00:05:18.009 --> 00:05:22.001
This is how you could do some data profiling in Excel.

139
00:05:22.001 --> 00:05:23.004
Kind of weird here.

140
00:05:23.004 --> 00:05:25.003
It's formatting this like a code snippet,

141
00:05:25.003 --> 00:05:26.009
but it's actually just text.

142
00:05:26.009 --> 00:05:29.001
It's telling me use data analysis tools,

143
00:05:29.001 --> 00:05:30.007
use conditional formatting,

144
00:05:30.007 --> 00:05:34.008
not really giving me any clear or actionable guidance there.

145
00:05:34.008 --> 00:05:36.002
Same story with this snippet.

146
00:05:36.002 --> 00:05:37.001
Little bit odd.

147
00:05:37.001 --> 00:05:38.009
It's telling me use pivot tables, charts,

148
00:05:38.009 --> 00:05:40.004
analysis tool pack,

149
00:05:40.004 --> 00:05:42.005
use multiple methods, be iterative,

150
00:05:42.005 --> 00:05:44.006
again, get help from an expert.

151
00:05:44.006 --> 00:05:46.004
Not really impressed with this output.

152
00:05:46.004 --> 00:05:48.003
I think this is where the difference

153
00:05:48.003 --> 00:05:51.002
between the two tools is really starting to shine.

154
00:05:51.002 --> 00:05:53.004
ChatGPT was a little bit more thorough

155
00:05:53.004 --> 00:05:55.005
and a little bit more specific.

156
00:05:55.005 --> 00:05:59.003
And I love that it offered actual formulas and functions

157
00:05:59.003 --> 00:06:01.007
and tools that I could apply,

158
00:06:01.007 --> 00:06:06.001
whereas the response from Bard is a little bit more generic.

159
00:06:06.001 --> 00:06:06.009
But overall,

160
00:06:06.009 --> 00:06:09.002
I got to say I'm pretty happy with these outputs.

161
00:06:09.002 --> 00:06:10.002
At the very least,

162
00:06:10.002 --> 00:06:12.006
they do cover a ton of best practices

163
00:06:12.006 --> 00:06:15.009
and important considerations when it comes to data QA

164
00:06:15.009 --> 00:06:16.009
and EDA,

165
00:06:16.009 --> 00:06:19.007
things like missing values, data types, outliers,

166
00:06:19.007 --> 00:06:21.006
normalization, so on.

167
00:06:21.006 --> 00:06:24.001
I love the conversational nature here,

168
00:06:24.001 --> 00:06:26.008
which allows you to really guide the conversation

169
00:06:26.008 --> 00:06:30.001
and focus on specific relevant topics.

170
00:06:30.001 --> 00:06:31.000
And to be honest,

171
00:06:31.000 --> 00:06:32.005
I think this would be a pretty good roadmap

172
00:06:32.005 --> 00:06:34.003
for an analyst to follow,

173
00:06:34.003 --> 00:06:36.005
especially if you have the technical chops

174
00:06:36.005 --> 00:06:38.009
to actually use all of the tools and techniques

175
00:06:38.009 --> 00:06:39.009
that it recommends.
